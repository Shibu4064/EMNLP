{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shibu4064/EMNLP/blob/main/Text_classification_using_BanglaBertTwitterRobertaCombined_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets\n",
        "!pip install transformers\n",
        "!pip install transformers[torch]\n",
        "# !pip install transformers[tf-cpu]\n",
        "# !pip install transformers[flax]\n",
        "!pip install torch\n",
        "!pip install tensorflow\n",
        "!pip install evaluate\n",
        "!pip install torchsummary\n",
        "!pip install gdown\n",
        "!pip uninstall jaxlib\n",
        "!pip install -U jax jaxlib"
      ],
      "metadata": {
        "id": "MEKqGN1FQdwC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "59ed49aa-27a8-4a36-84cb-bfaf2f2cb3c4"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.0)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.0.1+cu118)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.21.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (3.27.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (16.0.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.56.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.14)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.7.22)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Found existing installation: jaxlib 0.4.14\n",
            "Uninstalling jaxlib-0.4.14:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/jaxlib-0.4.14.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/jaxlib/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled jaxlib-0.4.14\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (0.4.14)\n",
            "Collecting jaxlib\n",
            "  Using cached jaxlib-0.4.14-cp310-cp310-manylinux2014_x86_64.whl (73.7 MB)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from jax) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax) (1.10.1)\n",
            "Installing collected packages: jaxlib\n",
            "Successfully installed jaxlib-0.4.14\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "jaxlib"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModelForSequenceClassification\n",
        "import pandas as pd\n",
        "import gdown"
      ],
      "metadata": {
        "id": "zmXaqQILinLg"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
        "bangla_bert = AutoModelForMaskedLM.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
        "twitter_roberta = AutoModelForSequenceClassification.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
        "\n",
        "bangla_bert_embedding_layer = bangla_bert.bert.embeddings\n",
        "twitter_roberta_encoding_layer = twitter_roberta.roberta.encoder\n",
        "\n",
        "\n",
        "base_model = twitter_roberta\n",
        "embedding_layer = bangla_bert_embedding_layer\n",
        "\n",
        "base_model.roberta.embeddings=embedding_layer\n",
        "\n",
        "\n",
        "\n",
        "# for param in base_model.roberta.embeddings.parameters():\n",
        "#   param.requires_grad=False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# for param in base_model.roberta.encoder.parameters():\n",
        "#   param.requires_grad=False\n",
        "\n",
        "# print(base_model.roberta.encoder.layer[0])\n",
        "\n",
        "# duitai comment koira abar run diben tarpore dekhen ki ashe\n",
        "# for name, param in base_model.roberta.encoder.named_parameters():\n",
        "#   print(name)\n",
        "\n",
        "# base_model.roberta.encoder.layer[11].requires_grad=False\n",
        "layers_num = range(11)\n",
        "# print(layers_num)\n",
        "\n",
        "# for layer in layers_num[-5:]:\n",
        "#   base_model.roberta.encoder.layer[layer].requires_grad=False\n",
        "\n",
        "# print(base_model)\n",
        "\n",
        "# dir(base_model.roberta.encoder.layer[0])\n",
        "# dir(base_model.roberta.encoder.parameters())\n",
        "# for param in base_model.roberta.encoder.parameters():\n",
        "#   print(param.requires_grad)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sff2CU8FeOQa",
        "outputId": "e48304da-d0a1-4e12-ae62-8b2d978a03b4"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at sagorsarker/bangla-bert-base were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in base_model.roberta.encoder.named_parameters():\n",
        "  print(name,param.requires_grad)"
      ],
      "metadata": {
        "id": "cBSQFWPmHsPh",
        "outputId": "f1044d39-3b5d-4283-9d4e-ecf2695d9612",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer.0.attention.self.query.weight True\n",
            "layer.0.attention.self.query.bias True\n",
            "layer.0.attention.self.key.weight True\n",
            "layer.0.attention.self.key.bias True\n",
            "layer.0.attention.self.value.weight True\n",
            "layer.0.attention.self.value.bias True\n",
            "layer.0.attention.output.dense.weight True\n",
            "layer.0.attention.output.dense.bias True\n",
            "layer.0.attention.output.LayerNorm.weight True\n",
            "layer.0.attention.output.LayerNorm.bias True\n",
            "layer.0.intermediate.dense.weight True\n",
            "layer.0.intermediate.dense.bias True\n",
            "layer.0.output.dense.weight True\n",
            "layer.0.output.dense.bias True\n",
            "layer.0.output.LayerNorm.weight True\n",
            "layer.0.output.LayerNorm.bias True\n",
            "layer.1.attention.self.query.weight True\n",
            "layer.1.attention.self.query.bias True\n",
            "layer.1.attention.self.key.weight True\n",
            "layer.1.attention.self.key.bias True\n",
            "layer.1.attention.self.value.weight True\n",
            "layer.1.attention.self.value.bias True\n",
            "layer.1.attention.output.dense.weight True\n",
            "layer.1.attention.output.dense.bias True\n",
            "layer.1.attention.output.LayerNorm.weight True\n",
            "layer.1.attention.output.LayerNorm.bias True\n",
            "layer.1.intermediate.dense.weight True\n",
            "layer.1.intermediate.dense.bias True\n",
            "layer.1.output.dense.weight True\n",
            "layer.1.output.dense.bias True\n",
            "layer.1.output.LayerNorm.weight True\n",
            "layer.1.output.LayerNorm.bias True\n",
            "layer.2.attention.self.query.weight True\n",
            "layer.2.attention.self.query.bias True\n",
            "layer.2.attention.self.key.weight True\n",
            "layer.2.attention.self.key.bias True\n",
            "layer.2.attention.self.value.weight True\n",
            "layer.2.attention.self.value.bias True\n",
            "layer.2.attention.output.dense.weight True\n",
            "layer.2.attention.output.dense.bias True\n",
            "layer.2.attention.output.LayerNorm.weight True\n",
            "layer.2.attention.output.LayerNorm.bias True\n",
            "layer.2.intermediate.dense.weight True\n",
            "layer.2.intermediate.dense.bias True\n",
            "layer.2.output.dense.weight True\n",
            "layer.2.output.dense.bias True\n",
            "layer.2.output.LayerNorm.weight True\n",
            "layer.2.output.LayerNorm.bias True\n",
            "layer.3.attention.self.query.weight True\n",
            "layer.3.attention.self.query.bias True\n",
            "layer.3.attention.self.key.weight True\n",
            "layer.3.attention.self.key.bias True\n",
            "layer.3.attention.self.value.weight True\n",
            "layer.3.attention.self.value.bias True\n",
            "layer.3.attention.output.dense.weight True\n",
            "layer.3.attention.output.dense.bias True\n",
            "layer.3.attention.output.LayerNorm.weight True\n",
            "layer.3.attention.output.LayerNorm.bias True\n",
            "layer.3.intermediate.dense.weight True\n",
            "layer.3.intermediate.dense.bias True\n",
            "layer.3.output.dense.weight True\n",
            "layer.3.output.dense.bias True\n",
            "layer.3.output.LayerNorm.weight True\n",
            "layer.3.output.LayerNorm.bias True\n",
            "layer.4.attention.self.query.weight True\n",
            "layer.4.attention.self.query.bias True\n",
            "layer.4.attention.self.key.weight True\n",
            "layer.4.attention.self.key.bias True\n",
            "layer.4.attention.self.value.weight True\n",
            "layer.4.attention.self.value.bias True\n",
            "layer.4.attention.output.dense.weight True\n",
            "layer.4.attention.output.dense.bias True\n",
            "layer.4.attention.output.LayerNorm.weight True\n",
            "layer.4.attention.output.LayerNorm.bias True\n",
            "layer.4.intermediate.dense.weight True\n",
            "layer.4.intermediate.dense.bias True\n",
            "layer.4.output.dense.weight True\n",
            "layer.4.output.dense.bias True\n",
            "layer.4.output.LayerNorm.weight True\n",
            "layer.4.output.LayerNorm.bias True\n",
            "layer.5.attention.self.query.weight True\n",
            "layer.5.attention.self.query.bias True\n",
            "layer.5.attention.self.key.weight True\n",
            "layer.5.attention.self.key.bias True\n",
            "layer.5.attention.self.value.weight True\n",
            "layer.5.attention.self.value.bias True\n",
            "layer.5.attention.output.dense.weight True\n",
            "layer.5.attention.output.dense.bias True\n",
            "layer.5.attention.output.LayerNorm.weight True\n",
            "layer.5.attention.output.LayerNorm.bias True\n",
            "layer.5.intermediate.dense.weight True\n",
            "layer.5.intermediate.dense.bias True\n",
            "layer.5.output.dense.weight True\n",
            "layer.5.output.dense.bias True\n",
            "layer.5.output.LayerNorm.weight True\n",
            "layer.5.output.LayerNorm.bias True\n",
            "layer.6.attention.self.query.weight True\n",
            "layer.6.attention.self.query.bias True\n",
            "layer.6.attention.self.key.weight True\n",
            "layer.6.attention.self.key.bias True\n",
            "layer.6.attention.self.value.weight True\n",
            "layer.6.attention.self.value.bias True\n",
            "layer.6.attention.output.dense.weight True\n",
            "layer.6.attention.output.dense.bias True\n",
            "layer.6.attention.output.LayerNorm.weight True\n",
            "layer.6.attention.output.LayerNorm.bias True\n",
            "layer.6.intermediate.dense.weight True\n",
            "layer.6.intermediate.dense.bias True\n",
            "layer.6.output.dense.weight True\n",
            "layer.6.output.dense.bias True\n",
            "layer.6.output.LayerNorm.weight True\n",
            "layer.6.output.LayerNorm.bias True\n",
            "layer.7.attention.self.query.weight True\n",
            "layer.7.attention.self.query.bias True\n",
            "layer.7.attention.self.key.weight True\n",
            "layer.7.attention.self.key.bias True\n",
            "layer.7.attention.self.value.weight True\n",
            "layer.7.attention.self.value.bias True\n",
            "layer.7.attention.output.dense.weight True\n",
            "layer.7.attention.output.dense.bias True\n",
            "layer.7.attention.output.LayerNorm.weight True\n",
            "layer.7.attention.output.LayerNorm.bias True\n",
            "layer.7.intermediate.dense.weight True\n",
            "layer.7.intermediate.dense.bias True\n",
            "layer.7.output.dense.weight True\n",
            "layer.7.output.dense.bias True\n",
            "layer.7.output.LayerNorm.weight True\n",
            "layer.7.output.LayerNorm.bias True\n",
            "layer.8.attention.self.query.weight True\n",
            "layer.8.attention.self.query.bias True\n",
            "layer.8.attention.self.key.weight True\n",
            "layer.8.attention.self.key.bias True\n",
            "layer.8.attention.self.value.weight True\n",
            "layer.8.attention.self.value.bias True\n",
            "layer.8.attention.output.dense.weight True\n",
            "layer.8.attention.output.dense.bias True\n",
            "layer.8.attention.output.LayerNorm.weight True\n",
            "layer.8.attention.output.LayerNorm.bias True\n",
            "layer.8.intermediate.dense.weight True\n",
            "layer.8.intermediate.dense.bias True\n",
            "layer.8.output.dense.weight True\n",
            "layer.8.output.dense.bias True\n",
            "layer.8.output.LayerNorm.weight True\n",
            "layer.8.output.LayerNorm.bias True\n",
            "layer.9.attention.self.query.weight True\n",
            "layer.9.attention.self.query.bias True\n",
            "layer.9.attention.self.key.weight True\n",
            "layer.9.attention.self.key.bias True\n",
            "layer.9.attention.self.value.weight True\n",
            "layer.9.attention.self.value.bias True\n",
            "layer.9.attention.output.dense.weight True\n",
            "layer.9.attention.output.dense.bias True\n",
            "layer.9.attention.output.LayerNorm.weight True\n",
            "layer.9.attention.output.LayerNorm.bias True\n",
            "layer.9.intermediate.dense.weight True\n",
            "layer.9.intermediate.dense.bias True\n",
            "layer.9.output.dense.weight True\n",
            "layer.9.output.dense.bias True\n",
            "layer.9.output.LayerNorm.weight True\n",
            "layer.9.output.LayerNorm.bias True\n",
            "layer.10.attention.self.query.weight True\n",
            "layer.10.attention.self.query.bias True\n",
            "layer.10.attention.self.key.weight True\n",
            "layer.10.attention.self.key.bias True\n",
            "layer.10.attention.self.value.weight True\n",
            "layer.10.attention.self.value.bias True\n",
            "layer.10.attention.output.dense.weight True\n",
            "layer.10.attention.output.dense.bias True\n",
            "layer.10.attention.output.LayerNorm.weight True\n",
            "layer.10.attention.output.LayerNorm.bias True\n",
            "layer.10.intermediate.dense.weight True\n",
            "layer.10.intermediate.dense.bias True\n",
            "layer.10.output.dense.weight True\n",
            "layer.10.output.dense.bias True\n",
            "layer.10.output.LayerNorm.weight True\n",
            "layer.10.output.LayerNorm.bias True\n",
            "layer.11.attention.self.query.weight True\n",
            "layer.11.attention.self.query.bias True\n",
            "layer.11.attention.self.key.weight True\n",
            "layer.11.attention.self.key.bias True\n",
            "layer.11.attention.self.value.weight True\n",
            "layer.11.attention.self.value.bias True\n",
            "layer.11.attention.output.dense.weight True\n",
            "layer.11.attention.output.dense.bias True\n",
            "layer.11.attention.output.LayerNorm.weight True\n",
            "layer.11.attention.output.LayerNorm.bias True\n",
            "layer.11.intermediate.dense.weight True\n",
            "layer.11.intermediate.dense.bias True\n",
            "layer.11.output.dense.weight True\n",
            "layer.11.output.dense.bias True\n",
            "layer.11.output.LayerNorm.weight True\n",
            "layer.11.output.LayerNorm.bias True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in base_model.named_parameters():\n",
        "    print(f'Layer: {name}, Trainable: {param.requires_grad}')"
      ],
      "metadata": {
        "id": "mIKsZzKv3b1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bangla_bert = AutoModelForMaskedLM.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
        "\n",
        "tokenizer_name = 'sagorsarker/bangla-bert-base'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, use_fast=True)\n",
        "\n",
        "train_texts = [\"আমার কিছু ভালো লাগে না\",\"আমার সব কিছুই ভালো লাগে\"]\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "\n",
        "output = base_model(torch.tensor(train_encodings[\"input_ids\"]))\n",
        "\n",
        "(output[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FK5DzpE9z6tQ",
        "outputId": "4bd544ca-f5ea-4fdf-9462-4c255e4fa1e8"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at sagorsarker/bangla-bert-base were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.1734,  1.8127, -0.8469],\n",
              "        [-2.1424,  1.8171,  0.5028]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "train_data_link = \"https://drive.google.com/uc?id=1yWabvxdMa6GWaE_K6cVNI0TylCP3MYHg\"\n",
        "gdown.download(train_data_link,\"train.csv\")\n",
        "\n",
        "val_data_link = \"https://drive.google.com/uc?id=1uCHk3x81Jfw3iL-WlKtnK0dC-j7pxbyL\"\n",
        "gdown.download(val_data_link,\"val.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "Fgm77MroS82R",
        "outputId": "8d0cb934-b189-4165-e773-417c040532f5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1yWabvxdMa6GWaE_K6cVNI0TylCP3MYHg\n",
            "To: /content/train.csv\n",
            "100%|██████████| 345k/345k [00:00<00:00, 90.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uCHk3x81Jfw3iL-WlKtnK0dC-j7pxbyL\n",
            "To: /content/val.csv\n",
            "100%|██████████| 725k/725k [00:00<00:00, 125MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'val.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "val_df = pd.read_csv(\"val.csv\")"
      ],
      "metadata": {
        "id": "MD-q8ey74YSz"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def pandaToList(dataset):\n",
        "    text_list = []\n",
        "    label_list = []\n",
        "    for i in range(len(dataset['text'])):\n",
        "      text_list.append(dataset['text'][i])\n",
        "      label_list.append(int(dataset['label'][i]))\n",
        "    return text_list, label_list\n",
        "\n",
        "train_texts, train_labels =  pandaToList(train_df)\n",
        "val_texts, val_labels = pandaToList(val_df)"
      ],
      "metadata": {
        "id": "qXRIb1ivVhUu"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_name = 'sagorsarker/bangla-bert-base'\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, use_fast=True)"
      ],
      "metadata": {
        "id": "z4u-gloBn-UJ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True)"
      ],
      "metadata": {
        "id": "ICFYyY5XoGLg",
        "outputId": "f502db3c-d640-4641-8757-4e9fcc524d23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class ViolenceDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = ViolenceDataset(train_encodings, train_labels)\n",
        "val_dataset = ViolenceDataset(val_encodings, val_labels)"
      ],
      "metadata": {
        "id": "nkdzBo9VoIGq"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "def compute_metrics(p):\n",
        "    pred, labels = p\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
        "    recall = recall_score(y_true=labels, y_pred=pred, average='macro')\n",
        "    precision = precision_score(y_true=labels, y_pred=pred, average='macro')\n",
        "    f1 = f1_score(y_true=labels, y_pred=pred, average='macro')\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n"
      ],
      "metadata": {
        "id": "tLpCB0kQoOiI"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import  Trainer, TrainingArguments, EarlyStoppingCallback, IntervalStrategy, AutoModelForSequenceClassification\n",
        "# EarlyStoppingCallback()"
      ],
      "metadata": {
        "id": "HDDbs7NfCBoK",
        "outputId": "ca8bad35-300a-4068-b296-a11d06feb26d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.trainer_callback.EarlyStoppingCallback"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import  Trainer, TrainingArguments, EarlyStoppingCallback, IntervalStrategy, AutoModelForSequenceClassification\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "   f\"training_with_callbacks\",\n",
        "   evaluation_strategy = IntervalStrategy.STEPS, # \"steps\"\n",
        "   #output_dir= output_dir,\n",
        "   eval_steps = 250, # Evaluation and Save happens every 250 steps\n",
        "   save_total_limit = 5, # Only last 5 models are saved. Older ones are deleted.\n",
        "\n",
        "   learning_rate=1e-5,\n",
        "   per_device_train_batch_size=8,\n",
        "   per_device_eval_batch_size=8,\n",
        "   num_train_epochs=100,\n",
        "   weight_decay=0.01,\n",
        "   metric_for_best_model = 'f1',\n",
        "   load_best_model_at_end=True)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=base_model,                         # the instantiated Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,            # evaluation dataset\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience=5,early_stopping_threshold=.5)]\n",
        ")\n"
      ],
      "metadata": {
        "id": "EvPE97Hwtw0y"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "VcKKz9EL3a7d",
        "outputId": "3df79eee-0fc3-4f91-8935-aaa261005695"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1750' max='16700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 1750/16700 09:57 < 1:25:14, 2.92 it/s, Epoch 10/100]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.025870</td>\n",
              "      <td>0.509630</td>\n",
              "      <td>0.387979</td>\n",
              "      <td>0.344976</td>\n",
              "      <td>0.284648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.933700</td>\n",
              "      <td>1.032051</td>\n",
              "      <td>0.504815</td>\n",
              "      <td>0.354748</td>\n",
              "      <td>0.343783</td>\n",
              "      <td>0.290338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.933700</td>\n",
              "      <td>1.031263</td>\n",
              "      <td>0.508148</td>\n",
              "      <td>0.342398</td>\n",
              "      <td>0.337060</td>\n",
              "      <td>0.259503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.995300</td>\n",
              "      <td>1.010600</td>\n",
              "      <td>0.501111</td>\n",
              "      <td>0.347395</td>\n",
              "      <td>0.344647</td>\n",
              "      <td>0.298162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.995300</td>\n",
              "      <td>1.010719</td>\n",
              "      <td>0.505556</td>\n",
              "      <td>0.350440</td>\n",
              "      <td>0.340364</td>\n",
              "      <td>0.277974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.994000</td>\n",
              "      <td>1.005290</td>\n",
              "      <td>0.508889</td>\n",
              "      <td>0.337650</td>\n",
              "      <td>0.334857</td>\n",
              "      <td>0.248540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.994000</td>\n",
              "      <td>1.008169</td>\n",
              "      <td>0.508148</td>\n",
              "      <td>0.340376</td>\n",
              "      <td>0.333414</td>\n",
              "      <td>0.242150</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1750, training_loss=0.9775001569475447, metrics={'train_runtime': 598.1605, 'train_samples_per_second': 222.348, 'train_steps_per_second': 27.919, 'total_flos': 1146187825977600.0, 'train_loss': 0.9775001569475447, 'epoch': 10.48})"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.predict(val_dataset)"
      ],
      "metadata": {
        "id": "e59T0gHS5RIS",
        "outputId": "e1693750-67c7-4333-8927-e0944f3b1a06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PredictionOutput(predictions=array([[ 0.23900491,  0.08940136, -0.62631345],\n",
              "       [ 0.20004222,  0.3858916 , -0.81519496],\n",
              "       [ 0.47950473,  0.1855433 , -0.990983  ],\n",
              "       ...,\n",
              "       [ 0.45391846,  0.00561585, -0.7398621 ],\n",
              "       [-0.03560179,  0.81374747, -0.7086271 ],\n",
              "       [ 0.6998488 ,  0.02383585, -0.96892804]], dtype=float32), label_ids=array([1, 0, 2, ..., 0, 0, 2]), metrics={'test_loss': 1.0234466791152954, 'test_accuracy': 0.49333333333333335, 'test_precision': 0.33552404270459535, 'test_recall': 0.33645608737741545, 'test_f1': 0.28562467172337525, 'test_runtime': 30.5246, 'test_samples_per_second': 88.453, 'test_steps_per_second': 11.073})"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    }
  ]
}